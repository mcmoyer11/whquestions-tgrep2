---
title: "Analysis of wh-questions"
author: "mcmoyer"
date: "October 22, 2020"
output: html_document
---
  
## Step 1: select stimuli for experiment
  
Set your path here and load some packages that are necessary for visualization 
(ggplot), tidy data handling (tidyr and dplyr), and mixed effects modeling (lme4:
                                                                                                                                                               
```{r}  
library(ggplot2)
library(tidyr)
library(dplyr)
library(lme4)
# theme_set(theme_bw())

this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../analysis/helpers.R")
```

Read the database into R and explore it.
```{r}
d = read.table("../results/swbd.tab",sep="\t",header=T,quote="")

# Load in the .csv with the contexts removed
# d = read.csv("swbd_nocntxt.csv",header=T)
View(d)
# old
nrow(d) # 10667.....10278....10192 (added MACRO (@WH > /^WH/)...10199 (@WH >> /^WH)
head(d)
str(d)
summary(d)

str(d)
table(d$QuestionType)
# Make sure there are none without a tag
nonya <- subset(d, d$QuestionType=="")
nrow(nonya)
# 
#  adjunct       cleft  embadjunct    embedded exclamation    fragment    relative        
#         775         586        2401        2432          34         126        1378        root     subject 
#         1719         748 


View(subset(d,d$QuestionType=="cleft"))
nrow(subset(d,d$QuestionType=="embedded"))

# randomly sample an embedded clause
d_emb = subset(d, d$QuestionType=="embedded")
d_crit = d_emb %>%
  filter(Wh %in% c("who","where","how"))
nrow(d_emb) # 3018 --> 2421
nrow(d_crit) #1087 --> 954
set.seed(123)
see <- sample_n(d_crit,30)
# names(see)
# look at just the columns of interest
View(see[,c("Item_ID","Sentence","MatrixPred1","InvertedAuxVerb","MatVerbPart","Question","SentenceParse")])

d[d["Item_ID"] == "331:188"] # shouldn't be embedded
d[d["Item_ID"] == "107183:17"] # shouldn't be embedded
d[d["Item_ID"] == "72099:29"]

```

so i mean, how i would go about *-1 doing it *t*-2 is i would just call all my relatives.
(TOP (S (RB so) 
        (PRN (S (NP-SBJ (PRP I)) (VP (VBP mean))) (, ,)) 
        (SBAR-NOM-SBJ (WHADVP-2 (WRB how)) (S (NP-SBJ-1 (PRP I)) (VP (MD would) (VP (VB go) (PRT (IN about)) (S (NP-SBJ (-NONE- *-1)) (VP (VBG doing) (NP (PRP it)))) (ADVP-MNR (-NONE- *T*-2)))))) (VP (VBZ is) (S-PRD (NP-SBJ (PRP I)) (VP (MD would) (ADVP (RB just)) (VP (VB call) (NP (DT all) (PRP$ my) (NNS relatives)))))) (. .) (-DFL- E_S)))

but they do read. uh, where a lot of people don't have any interest in it at all *t*-1,


Take a random sample of 200.
```{r}
set.seed(123)
s <- sample_n(d, 200)
View(s)
View(s[,c("Item_ID","QuestionType","Sentence","Question","SentenceParse")])

nrow(s)
# write to CSV

write.csv(s, "whq_sample_200.csv",row.names = TRUE)

s_emb = subset(s, s$QuestionType=="embedded")
View(s_emb)

```
https://github.com/thegricean/corpus_implicatures/tree/master/or/experiments/4_implicature_exp/experiments/02_main/experiment_00/js

https://github.com/thegricean/corpus_implicatures/blob/master/some/experiments/main_experiments/speaker_knowledge/experiment_01/public/js/stimuli.js
https://raw.githubusercontent.com/leylakursat/some_without_context/master/experiment/corpora/corpus1.txt

https://thegricean.github.io/corpus_implicatures/or/experiments/4_implicature_exp/experiments/02_main/experiment_00/index.html


Reproduce the same set
```{r}
# the original DF i sent jd
sa <- read.csv("whq_sample_200_A.csv", header=TRUE)


sa = sa[order(sa$Item_ID),]

# this will remove any columns that aren't shared 
ddnew = semi_join(sa, d, by=c("Item_ID"))
# drop that first column
ddnew = ddnew[-c(1)]
write.csv(ddnew, "whq_sample_200_neworig.csv",row.names = TRUE)

# try to check if they're the same IDs

ddnew_names = ddnew$Item_ID
sa_names = sa$Item_ID
length(sa_names)

all.equal(ddnew_names,sa_names)

View(ddnew)

# this doesn't remove any columns that aren't in sa
snew = d %>%
  filter(Item_ID %in% sa$Item_ID)

View(snew)
write.csv(snew, "whq_sample_200_neworig.csv",row.names = TRUE)
# save it to a csv file and provide an annotation guide for what 
# the different types of features should be
# overleaf. 
# 
```

# some embedded cases aren't printing a matrix verb
```{r}
emb <- subset(d, d$QuestionType=="embedded")
nrow(emb)


enmv = emb %>%
  filter(MatrixPred1 %in% c(""))
nrow(enmv) # 3333.....0! fixed
View(enmv)

```
Take a look at cases where there is no questionType assigned.
```{r}
no_qt = subset(d, d$QuestionType=="")
nrow(no_qt) # 1016....819....20....18...0!
View(no_qt)
```
Look at the modal and non-modal cases
```{r}

mod = subset(d, d$ModalPresent=="yes")
nrow(mod) # 895

nmod = subset(d, d$ModalPresent=="no")
nrow(nmod) # 9235

table(d$ModalPresent)

nf2 <- subset(d, d$Finite=="no") # YES THESE ARE ALL GOOD
nrow(nf2) #190....186?
View(nf2)
# sanity check
nf <- subset(d, d$Finite!="yes") 
nrow(nf) #186
View(nf)

# Do these return all the same ?
all.equal(nf,nf2) # TRUE
````
cases that are tagged neither as modal or non-modal



````{r}
notmod = subset(d, d$ModalPresent!="no" & d$ModalPresent!="yes")
nrow(notmod)
View(notmod)
str(d)
notmodcomp = d %>%
  filter(!ModalPresent %in% c("yes","no")) %>%
  filter(WhPhraseType %in% c("complex"))

notmodcomp2 = subset(notmod, notmod$WhPhaseType=="complex")
nrow(notmodcomp2) # so there are non-complex wh that are failing
notmodnotcomp = subset(notmod, notmod$WhPhaseType!="complex")
nrow(notmodnotcomp)
View(notmodnotcomp)

```


```{r}
dd = grepl("can|could|may|might|must|shall|should", d$Sentence)
View(dd)

mods <- ""
for (r in notmod){
    if (grepl("can|could|may|might|must|shall|should", notmod$Sentence))
    mods + r
  }
```

Graphssss

```{r}
ftable(d$QuestionType,d$ModalPresent)

agr = d %>%
  group_by(QuestionType,ModalPresent,Finite) %>%
  mutate(count = count(Sentence), prop_modal= ) %>%
  
  ggplot(d, aes(x=as.factor(QuestionType),y=as.factor(Finite), fill = as.factor(ModalPresent))) +
  geom_bar()
  
View(agr)

```

Looking at embedded questions
```{r}


```
