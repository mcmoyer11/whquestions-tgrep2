---
title: "Exploratory analysis of context"
author: Morgan Moyer
date: May 18, 2021
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../helpers.R")
```

# Read the data into r
```{r}
context = read.csv("total_data.csv") 
context$Task <- "context"

nocontext = read.csv("../05_06_experiment/data/no_rhetorical.csv")
nocontext = nocontext[,c("workerid","tgrep_id","ModalPresent","Modal","QuestionType","Question","Sentence","paraphrase","rating","Finite","Wh")]
nocontext$Task <- "nocontext"


d <- full_join(context,nocontext)
nrow(context) + nrow(nocontext)
nrow(d)
d$rating[d$rating < 0] = 0
```

# Plot the differences between context and no context
```{r, include=FALSE}
names(d)
ggplot(data = d, aes(x = rating, fill = paraphrase, color=paraphrase)) +
  geom_density(alpha = .4) +
  facet_grid(~Task)
 
agr = d %>%
  group_by(Task, tgrep_id,paraphrase) %>%
  summarize(mean_rating = mean(rating),sd = sd(rating))

# look at differences in mean_rating
ggplot(data = agr, aes(x = mean_rating, fill=Task, color=Task)) +
  geom_density(alpha = .4) +
  facet_grid(~paraphrase) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
ggsave("graphs/denisty_context_ratings.pdf",width=6,height=3)

# look at differences in SD 
ggplot(data = agr, aes(x = sd, fill=Task, color=Task)) +
  geom_density(alpha = .4) +
  facet_grid(~paraphrase) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
ggsave("graphs/denisty_context_sd.pdf",width=6,height=3)
```


# plot mean differences with linguistic factors too
```{r,include=FALSE}
# MODALPRESENT
agr = d %>%
  group_by(Task,ModalPresent,tgrep_id,paraphrase) %>%
  summarize(mean_rating = mean(rating),sd = sd(rating))

# look at differences in mean_rating
ggplot(data = agr, aes(x = mean_rating, fill=Task, color=Task)) +
  geom_density(alpha = .4) +
  facet_grid(ModalPresent~paraphrase) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
ggsave("graphs/denisty_context_MP_ratings.pdf",width=6,height=3)

# look at differences in SD 
ggplot(data = agr, aes(x = sd, fill=Task, color=Task)) +
  geom_density(alpha = .4) +
  facet_grid(ModalPresent~paraphrase) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
ggsave("graphs/denisty_context_MP_sd.pdf",width=6,height=3)

# WH
agr = d %>%
  group_by(Task,Wh,tgrep_id,paraphrase) %>%
  summarize(mean_rating = mean(rating),sd = sd(rating))

# look at differences in mean_rating
ggplot(data = agr, aes(x = mean_rating, fill=Task, color=Task)) +
  geom_density(alpha = .4) +
  facet_grid(Wh~paraphrase) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
```

# Calculate KL-Divergence

## Aggregate ratings and renormalize
```{r}
agr <- d %>%
    group_by(Task,tgrep_id,paraphrase) %>%
    summarize(mean_rating = mean(rating))

agr$factors = paste(agr$Task,agr$tgrep_id,agr$paraphrase)
cr = agr %>%
  # select(ids,rating) %>%
  group_by(tgrep_id) %>%
  summarize(rating_sum = sum(mean_rating))

# # Join the dfs together
agr = agr %>%
  left_join(cr, by="tgrep_id")
View(agr)
# For each of the paraphrase ratings, divide by sum of ratings for that item
normed = agr %>%
  group_by(factors) %>%
  summarise(normed_rating = mean_rating/rating_sum) %>%
  drop_na() %>% # this removes ALOT of rows
  left_join(agr, by="factors")

```

## Convert from long to wide so can compute the four ratings as a vector/list 
for each tgrep_id
```{r}
d_wide = normed %>% 
  group_by(tgrep_id) %>%
  spread(paraphrase, normed_rating) %>%
  # collapse all the duplicates
  summarise_all(funs(.[which(!is.na(.))])) # this is no longer working :/
# d_wide = d_wide[,c("workerid","tgrep_id","a","every","other","the")]
# d_wide <- unique(d_wide)
```


## Calculate KL-Divergence, compare to the uniform distribution
KLD(P || Q) = sum x in X: (P(x) * log2(P(x)/Q(x)))
```{r}
# # log2(P/Q)
pre_kld <- function(x) {
    l <- log2(x/.25) # divide by the uniform distribution
    m <- ifelse(is.na(x),0,x * l)
  # }
  return(m)
}

kl_divergence <- function(x) {
  for (row in 1:nrow(x)) {
    pp <- pre_kld(x[,row])
    p <- ifelse(is.na(pp),0,pp)
    sum.p <- Reduce(`+`, p) # if you feed in a df slice, then it's a list
    # sum.p <- sum(p) # if you feed in a vector, then you can use sum()
    return(sum.p)
  }
}
d_wide$KLD_from_uniform <- kl_divergence(d_wide[,3:6])
```


```{r}


d_long <- d_wide %>%
  gather(paraphrase, mean_rating,a:the,factor_key=TRUE)

ggplot(data = d_long, aes(x = KLD_from_uniform, fill=Task, color=Task)) +
  geom_density(alpha = .4) +
  facet_wrap(~paraphrase) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
# ggsave("graphs/denisty_context_MP_sd.pdf",width=6,height=3)

```